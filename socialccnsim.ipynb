{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3944ad9d-0e2f-434d-a6e3-a70d53b61020",
   "metadata": {},
   "source": [
    "## 0 Import all neccesary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9501099f-b883-4dd7-814e-4ed88db25180",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Within AS\n",
    "# Caching Rate\n",
    "import random\n",
    "from multiprocessing import Queue\n",
    "import sys\n",
    "import sqlite3\n",
    "\n",
    "import re\n",
    "import optparse\n",
    "import logging\n",
    "import numpy\n",
    "import logging\n",
    "from visualize import visualizer as vis\n",
    "\n",
    "\n",
    "import threading\n",
    "from user import User\n",
    "\n",
    "import sched, time\n",
    "from topology_manager import TopologyManager, Paths, SocialPaths\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "from zipf import gen_biased_zipf_requests, gen_zipf_requests, gen_bilateral_biased_zipf_requests\n",
    "from Autonomous_System import AS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f520671a-8659-4f2a-b7de-811b0539b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipf_generator(num_of_content = 100, num_of_request = 1000, offset = 0):\n",
    "    alpha = 1\n",
    "    req, pattern = gen_bilateral_biased_zipf_requests(alpha = 1,number_of_content = num_of_content, number_of_request = num_of_request, offset = offset)\n",
    "    return pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b5fafaf-a949-416f-86b0-31f6d17eb02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pattern = zipf_generator(num_of_content = 100, num_of_request = 1000, offset = 0)\n",
    "plt.plot(pattern.keys(), pattern.values())\n",
    "plt.title('request pattern')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3761f669-0898-4236-bb47-799e802f3783",
   "metadata": {},
   "source": [
    "## 1 Prepare instruaction parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f89e48cd-14e6-469f-9d07-81dbbcb4f366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Option at 0x1220a2a60: -v/--verbose>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = optparse.OptionParser()\n",
    "parser.add_option(\"-c\", \"--cache-size-per-node\",\n",
    "              dest=\"cache_size_per_node\",\n",
    "              help=\"space of cache allocated for every node in the topology\",\n",
    "              type=int,\n",
    "              )\n",
    "parser.add_option(\"-s\", \"--strategy\",\n",
    "              dest=\"caching_strategy\",\n",
    "              help=\"caching Strategy used for evaluating the trace\"\n",
    "              )\n",
    "parser.add_option(\"-u\", \"--social-connections\",\n",
    "              dest=\"social_graph\",\n",
    "              help='social connections between users of the trace. Every trace includes users that executes actions.'\n",
    ")\n",
    "parser.add_option(\"-t\", \"--topology\",\n",
    "              dest=\"network_topology\",\n",
    "              help='network topology used for executing the trace.'\n",
    ")\n",
    "parser.add_option(\"-f\", \"--trace-file\",\n",
    "              dest=\"trace\",\n",
    "              default=\"\",\n",
    "              help='the trace to be executed',\n",
    ")\n",
    "parser.add_option(\"-p\", \"--replacement-policy\",\n",
    "              dest=\"replacement_policy\",\n",
    "              help='replacement policy used at every network node.',\n",
    ")\n",
    "parser.add_option(\"-m\", \"--mobility-enabled\",\n",
    "              dest=\"mobility_enabled\",\n",
    "              default=False,\n",
    "              action=\"store_true\",\n",
    "              help=\"Enable mobility of users\"\n",
    ")\n",
    "parser.add_option(\"-d\", \"--debug\",\n",
    "              dest=\"debug\",\n",
    "              default=False,\n",
    "              action=\"store_true\",\n",
    "              help=\"Enable debugging options\"\n",
    ")\n",
    "parser.add_option(\"-r\", \"--step-printing\",\n",
    "              dest=\"step_printing\",\n",
    "              default=\"\",\n",
    "              help = \"\"\n",
    ")\n",
    "parser.add_option(\"-z\", \"--zipf\",\n",
    "              dest=\"zipf\",\n",
    "              default=False,\n",
    "              action=\"store_true\",\n",
    "              help = \"\"\n",
    ")\n",
    "parser.add_option(\"-e\", \"--method\",\n",
    "                 dest = \"method\",\n",
    "                 default='random',\n",
    "                 help = \"random/geographical/onepublisher\"\n",
    ")\n",
    "parser.add_option(\"-g\", \"--single-user\",\n",
    "                 dest = \"single\",\n",
    "                 default=False,\n",
    "                 action=\"store_true\",\n",
    "                 help = \"if set, each topology node comes with only one user\"\n",
    ")\n",
    "parser.add_option(\"-v\", \"--verbose\",\n",
    "                 dest = \"verbose\",\n",
    "                 default=False,\n",
    "                 action=\"store_true\",\n",
    "                 help = \"if set, print cache storage info\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afafda61-3925-4fc5-adbd-9ece821881b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger(logger_name, log_file, level=logging.INFO, format_style = '%(asctime)-15s %(message)s',verbose=True):\n",
    "    l = logging.getLogger(logger_name)\n",
    "    formatter = logging.Formatter(format_style)\n",
    "    fileHandler = logging.FileHandler(log_file, mode='w')\n",
    "    fileHandler.setFormatter(formatter)\n",
    "    l.addHandler(fileHandler)\n",
    "    streamHandler = logging.StreamHandler()\n",
    "    streamHandler.setFormatter(formatter)\n",
    "    l.addHandler(streamHandler)\n",
    "    l.setLevel(level)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "elder-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Executor(object):\n",
    "    def __init__(self, logger, social_graph, topology, cache_size, caching_strategy, cache_policy, sequence_filename = '', mobility_enabled = False, step_printing = [], topology_file = None, zipf = False, method = 'random', single = False, verbose = False):\n",
    "        self.lock = threading.Lock()\n",
    "        self.condition = threading.Condition()\n",
    "        #########################################\n",
    "        #Initialize AS\n",
    "        ##########################################\n",
    "        nodes = list(topology.nodes())\n",
    "        try:\n",
    "            nodes.remove(\"server\")\n",
    "        except:\n",
    "            pass\n",
    "        self.AS = AS(nodes, True)\n",
    "        logger.info(\"initialized Autonomous System\")\n",
    "        #########################################\n",
    "        # Configuration\n",
    "        #########################################\n",
    "        self.round = 0\n",
    "        ## Configure Cache\n",
    "        self.num_of_request = 2000\n",
    "        self.initialized_server = False\n",
    "        self.num_of_content = 1000\n",
    "        self.contents = [\"/content/%s\"%str(i) for i in range(self.num_of_content)]\n",
    "        #########################################\n",
    "        self.conf = {}\n",
    "        self.conf['caching_strategy'] = caching_strategy\n",
    "        self.conf['cache_policy'] = cache_policy\n",
    "        self.conf['sequence_from_file'] = sequence_filename != ''\n",
    "        self.conf['step_printing'] = step_printing\n",
    "        self.method = method\n",
    "        self.zipf_para = 1\n",
    "        if self.conf['step_printing'] != None:\n",
    "            self.steps = 0\n",
    "        else:\n",
    "            self.steps = None\n",
    "        self.verbose = verbose\n",
    "        #print(\"singledemo\",single)\n",
    "        #print(\"zipfdemo\",zipf)\n",
    "\n",
    "        ##########################################3\n",
    "        # The topology manager handles user connection to CCN nodes.\n",
    "        self.request_nodes = list(topology)\n",
    "        self.topology = topology\n",
    "        self.add_server_node()\n",
    "        if single:\n",
    "            self.social_nodes = self.topology\n",
    "        ##############################################\n",
    "        # Debugging\n",
    "        #print(self.topology.nodes())\n",
    "        logger.debug('Topology manager, connect users started')\n",
    "        topology_coords = nx.spring_layout(topology)\n",
    "        #topology_coords = {}\n",
    "        #for node in topology.nodes():\n",
    "        #    topology_coords[node] = (\n",
    "        #            random.randint(0, 100),\n",
    "        #            random.randint(0, 100)\n",
    "        #    )\n",
    "        self.topology_coords = topology_coords\n",
    "        if single:\n",
    "            self.social_graph = self.topology\n",
    "            self.topology_nodes = TopologyManager(self.topology, self.topology, topology_coords, mobility_enabled, topology_file = topology_file)\n",
    "        else:\n",
    "            self.topology_nodes = TopologyManager(self.topology, self.social_graph, topology_coords, mobility_enabled, topology_file = topology_file)\n",
    "        # 社交用户与节点之间关系为随机指定型\n",
    "        # 后续的请求是用户发出的，所以，主要是要看如何将用户与请求 Pattern之间建立起关系\n",
    "        self.topology_nodes.set_method(self.method)\n",
    "        # 从网络中随机初始化网络节点\n",
    "        # 从Social Network中随机初始化社交节点位置\n",
    "        if not single:\n",
    "            for user in social_graph.nodes():\n",
    "                # update user node(user,pos)\n",
    "                # initiate user position(coords_user)\n",
    "                # 将用户映射到最近的拓扑节点上\n",
    "                self.topology_nodes.update_user_position(user,(random.randint(0, 100), random.randint(0, 100)))\n",
    "            self.topology_nodes.update_all_users_position()\n",
    "        else:\n",
    "            # 在单用户场景中，我们需要将用户初始化于相应的节点中\n",
    "            for node in topology.nodes():\n",
    "                    #TODO\n",
    "                    self.topology_nodes.update_user_node(node,node)\n",
    "        logger.debug('Topology manager, connect users finished')\n",
    "\n",
    "        #\n",
    "        self.users = {}\n",
    "        for user in self.social_graph.nodes():\n",
    "            self.users[user] = User(user)\n",
    "\n",
    "        logger.debug('Start simulation')\n",
    "        # debugging\n",
    "        #print(self.topology_nodes.paths._path)\n",
    "\n",
    "        self.sched = sched.scheduler(time.time, time.sleep)\n",
    "\n",
    "        # Generate Sequence\n",
    "        #print \"generate sequence\"\n",
    "        if sequence_filename == '':\n",
    "            self.generate_sequence()\n",
    "        else:\n",
    "            self.initialize_scheduler_from_file(sequence_filename)\n",
    "\n",
    "        # Initialize Caches\n",
    "        self.lock.acquire()\n",
    "        # !!Cache Strategy Upper\n",
    "        caching_strategy_upper = self.conf['caching_strategy'].upper()\n",
    "        cm = getattr(getattr(__import__('cache_management.%s'%caching_strategy_upper), caching_strategy_upper), caching_strategy_upper)\n",
    "        self.caches = cm(\n",
    "                self.conf['cache_policy'],\n",
    "                cache_size,\n",
    "                self.social_graph,\n",
    "                self.topology,\n",
    "                self.topology_nodes,\n",
    "                threshold = None\n",
    "        )\n",
    "        logger.debug('Loaded caching strategy')\n",
    "        self.lock.release()\n",
    "        self.initialize_catalog()\n",
    "        ##//Initiate\n",
    "\n",
    "    \n",
    "    def initialize_scheduler(self, offset = 0):\n",
    "        self.sched = sched.scheduler(time.time, time.sleep)\n",
    "        ########################\n",
    "        # TODO 接上Server\n",
    "        if not self.initialized_server:\n",
    "            self.initialize_Server()\n",
    "            self.initialized_server = True\n",
    "        ##########################\n",
    "        #self.extract_sequence()\n",
    "        #########################\n",
    "        # Pending\n",
    "        # 插入ZipF请求\n",
    "        print(\"Start Simulating!\")\n",
    "        self.gen_zipf_sequence(num_of_content = self.num_of_content, num_of_request = self.num_of_request, r = self.round, offset = offset)\n",
    "        ######################\n",
    "\n",
    "        assert not self.sched.empty()\n",
    "\n",
    "\n",
    "    ##############################################\n",
    "    #TODO: currently not being used\n",
    "    def initialize_scheduler_from_file(self, filename):\n",
    "        self.seq_file = open(filename, 'r')\n",
    "        self.seq_n = 0\n",
    "    \n",
    "    def extract_sequence(self):\n",
    "        line = self.seq_file.readline()\n",
    "        while line != '': #Empty line, we reach the end of the sequence\n",
    "            # Retrieve fields in a line\n",
    "            # Line format\n",
    "            # |timestamp | event | User | mobility_x | mobility_y\n",
    "            result = re.match (\"(?P<timestamp>[0-9]*\\.[0-9]+)\\t(?P<activity>Retrieve|Publish|retrieve|publish|Retrievecontent|Publishcontent)\\t(?P<user>[0-9]+)\\t\\((?P<dependent>.*)\\)\\t\\((?P<mobility_x>[0-9\\.]*), ?(?P<mobility_y>[0-9\\.]*)\\)\", line)\n",
    "            if result != None:\n",
    "                #print step result\n",
    "                if self.steps != None and self.steps < len(self.conf['step_printing']) and float(result.group('timestamp')) > self.conf['step_printing'][self.steps]:\n",
    "                    # debugging\n",
    "                    print(self.steps)\n",
    "                    self.sched.enter(self.seq_n * 0.01, 0, self.printStepSummary, (self.conf['step_printing'][self.steps],))\n",
    "                    self.steps += 1\n",
    "                # schedule an event (delay, priority, action, argument=())\n",
    "                # delay, priority, action, argument=()\n",
    "                # 使用的工具为：\n",
    "                # 1 Producer2\n",
    "                # 2 consumer\n",
    "                # 3 consume_from_server\n",
    "                pos = (float(result.group('mobility_x')), float(result.group('mobility_y')))\n",
    "                if result.group('activity').lower() in ['publishcontent', 'publish']:\n",
    "                    self.sched.enter(self.seq_n * 0.01, 0, self.producer2, (int(result.group('user')), pos, \"/content/%s\"%result.group('dependent').split(',')[0] ))\n",
    "                # 两类consumer\n",
    "                elif result.group(2).lower() == 'retrieve':\n",
    "                    self.sched.enter(self.seq_n * 0.01, 0, self.consumer, (int(result.group('user')), pos,))\n",
    "                elif result.group(2).lower() == 'retrievecontent':\n",
    "                    #print(self.seq_n * 0.01, 0,self.consume_from_server, (int(result.group('user'))), pos, \"/content/%s\"%result.group('dependent').split(',')[0])\n",
    "                    self.sched.enter(self.seq_n * 0.01, 0, self.consume_from_server, (int(result.group('user')), pos, \"/content/%s\"%result.group('dependent').split(',')[0]))\n",
    "            else:\n",
    "                print(\"repr line: %s\"%repr(line))\n",
    "                exit(-1)\n",
    "            self.seq_n+=1\n",
    "            line=self.seq_file.readline()\n",
    "    def initialize_catalog(self):\n",
    "        self.f = tempfile.NamedTemporaryFile(delete=True, dir='/tmp/')\n",
    "        self.conn = sqlite3.connect(self.f.name)\n",
    "        self.c = self.conn.cursor()\n",
    "\n",
    "        #c.execute('''DROP table catalog''')\n",
    "        self.c.execute('''CREATE TABLE catalog\n",
    "                     (content_name text, publisher int, date double, refer text, refered_level int, topic int)''')\n",
    "\n",
    "    def generate_sequence(self, sequence = []):\n",
    "        assert type(sequence) == list\n",
    "        if sequence == []:\n",
    "            self.sequence = [random.randint(0, len(self.social_graph.nodes())-1) \\\n",
    "                for i in range(0, len(self.social_graph)*40)]\n",
    "            random.shuffle(self.sequence)\n",
    "        else:\n",
    "            self.sequence = sequence\n",
    "\n",
    "    ###################################\n",
    "    # 加入Server节点\n",
    "    def add_server_node(self):\n",
    "        node = random.choice(list(self.topology.nodes()))\n",
    "        self.topology.add_node(\"server\")\n",
    "        self.topology.add_edge(node,\"server\")\n",
    "        self.server = \"server\"\n",
    "    ############################################\n",
    "    # Initialize Server\n",
    "    # 随机选取一个节点\n",
    "    # 作为Server接上内容\n",
    "    def initialize_Server(self):\n",
    "        #################################\n",
    "        # TODO\n",
    "        # 找到中心节点\n",
    "        # 加入一个Server节点\n",
    "        # Pending\n",
    "        for content in self.contents:\n",
    "            self.sched.enter(self.seq_n * 0.01, 0, self.producer3, (self.server, content))\n",
    "        #################################\n",
    "\n",
    "    #################################\n",
    "    # 生成符合Zipf分布的请求，并插入仿真器中\n",
    "    # TODO:a Zipf sequence generator\n",
    "    # Pending 01 将请求插入进编辑器中\n",
    "    #def generate_Zipf_sequence(self,sequence = []):\n",
    "    def zipf_generator(self,num_of_content, num_of_request, offset):\n",
    "        alpha = self.zipf_para\n",
    "        req, _ = gen_bilateral_biased_zipf_requests(alpha = alpha,number_of_content = num_of_content, number_of_request = num_of_request, offset = offset)\n",
    "        return req\n",
    "        \n",
    "    def gen_zipf_sequence(self, num_of_content = 1000, num_of_request = 10000, r = 0, offset = 0):\n",
    "        sequence = self.zipf_generator(num_of_content, 10*num_of_content, offset)\n",
    "        if len(sequence)>=num_of_request:\n",
    "            requests = sequence[:num_of_request]\n",
    "        else:\n",
    "            while(num_of_content):\n",
    "                requests += sequence[:min(num_of_sequence,len(sequence))]\n",
    "        #consume_from_server(user,position, contentname)\n",
    "        # nodes must convert to list, or error appears\n",
    "        for request in requests:\n",
    "            ##############################################\n",
    "            if self.steps != None and self.steps < len(self.conf['step_printing']) and float(result.group('timestamp')) > self.conf['step_printing'][self.steps]:\n",
    "                    self.sched.enter(self.seq_n * 0.01, 0, self.printStepSummary, (self.conf['step_printing'][self.steps],))\n",
    "                    self.steps += 1\n",
    "            ##############################################\n",
    "            request_node = random.choice(self.request_nodes)\n",
    "            while(request_node == \"server\"):\n",
    "                request_node = random.choice(self.request_nodes)\n",
    "            #consume_from_server(user,position, contentname)\n",
    "            #目标是先从目标节点进行查找\n",
    "            ## Scheduler 的用法\n",
    "            # scheduler.enter(delay, priority, action, argument=(), kwargs={})\n",
    "            # Pending# consume from server 应该被改成从目标中获取\n",
    "            #print(self.social_graph.nodes())\n",
    "            #pos = self.topology_coords[request_node]\n",
    "            #self.sched.enter(self.seq_n * 0.01, 0, self.consume_from_server, (int(result.group('user')), pos, \"/content/%s\"%result.group('dependent').split(',')[0]))\n",
    "            req = self.contents[request]\n",
    "            # print(request_node, type(pos), type(req))\n",
    "            # print(self.seq_n * 0.01, 0, self.consume_from_server, request_node, pos, req)\n",
    "            self.sched.enter(self.seq_n * 0.01, 0, self.consume_from_target, (request_node, req))\n",
    "            self.seq_n+=1\n",
    "        print(\"total seq num: \",self.seq_n)\n",
    "     #################################\n",
    "    \n",
    "    def run(self, offset = 0):\n",
    "        #print \"the process begins\"\n",
    "        self.initialize_scheduler(offset = offset)\n",
    "        self.sched.run()\n",
    "        self.round += 1\n",
    "        time.sleep(2)\n",
    "\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.conn.close()\n",
    "    # 使用的是这一个！！\n",
    "    # 将文件插入到数据库中\n",
    "    def producer3(self, social_publisher, content, reference = '', topic = 0):\n",
    "        #self.topology_nodes.update_user_position(social_publisher, position)\n",
    "        self.caches.incr_publish()\n",
    "        #content_name = \"/friend%i/%i\"%(social_publisher, self.stats.increase_messages())\n",
    "        #print(\"node\",social_publisher, \"publish\",content)\n",
    "        content_name = \"%s\"%content\n",
    "        _new_content_name = content_name\n",
    "        if reference == '':\n",
    "            _ref_level = 0\n",
    "        else:\n",
    "            #Select \n",
    "            _ref_level = 0\n",
    "            for row in self.c.execute('SELECT * FROM catalog WHERE content_name=\\\"%s\\\" LIMIT 1'%reference):\n",
    "                _ref_level = row[4]+1\n",
    "                _new_content_name = row[0]\n",
    "                topic = row[5]\n",
    "            assert _ref_level == 1, _ref_level\n",
    "        self.c.execute(\"INSERT INTO catalog VALUES (\\\"%s\\\",'%s', '%s', '%s', %d, %d);\"%(content_name, social_publisher, time.time(), reference, _ref_level, topic))\n",
    "        self.lock.acquire()\n",
    "        self.caches.post_production(_new_content_name, social_publisher)\n",
    "        self.lock.release()\n",
    "    # 使用的是这一个！！\n",
    "    # 将文件插入到数据库中\n",
    "    def producer2(self, social_publisher, position, content, reference = '', topic = 0):\n",
    "        self.topology_nodes.update_user_position(social_publisher, position)\n",
    "        self.caches.incr_publish()\n",
    "        #content_name = \"/friend%i/%i\"%(social_publisher, self.stats.increase_messages())\n",
    "        #print(\"node\",social_publisher, \"publish\",content)\n",
    "        content_name = \"%s\"%content\n",
    "        _new_content_name = content_name\n",
    "        if reference == '':\n",
    "            _ref_level = 0\n",
    "        else:\n",
    "            #Select \n",
    "            _ref_level = 0\n",
    "            for row in self.c.execute('SELECT * FROM catalog WHERE content_name=\\\"%s\\\" LIMIT 1'%reference):\n",
    "                _ref_level = row[4]+1\n",
    "                _new_content_name = row[0]\n",
    "                topic = row[5]\n",
    "            assert _ref_level == 1, _ref_level\n",
    "        self.c.execute(\"INSERT INTO catalog VALUES (\\\"%s\\\",'%s', '%s', '%s', %d, %d);\"%(content_name, social_publisher, time.time(), reference, _ref_level, topic))\n",
    "        self.lock.acquire()\n",
    "        self.caches.post_production(_new_content_name, social_publisher)\n",
    "        self.lock.release()\n",
    "    ## Producer with position This is already abandoned~\n",
    "    def producer(self, social_publisher, position, reference = '', topic = 0):\n",
    "        logger.error(\"WARNING, this function is deprecated\")\n",
    "        exit(-1)\n",
    "        self.topology_nodes.update_user_position(social_publisher, position)\n",
    "        self.caches.incr_publish()\n",
    "        content_name = \"/friend%i/%i\"%(social_publisher, self.stats.increase_messages())\n",
    "        _new_content_name = content_name\n",
    "        if reference == '':\n",
    "            _ref_level = 0\n",
    "            topic = self.users[social_publisher].decide_next_topic()\n",
    "        else:\n",
    "            #Select \n",
    "            _ref_level = 0\n",
    "            for row in self.c.execute('SELECT * FROM catalog WHERE content_name=\\\"%s\\\" LIMIT 1'%reference):\n",
    "                _ref_level = row[4]+1\n",
    "                _new_content_name = row[0]\n",
    "                topic = row[5]\n",
    "            assert _ref_level == 1, _ref_level\n",
    "        self.c.execute(\"INSERT INTO catalog VALUES (\\\"%s\\\",'%s', '%s', '%s', %d, %d);\"%(content_name, social_publisher, time.time(), reference, _ref_level, topic))\n",
    "        self.lock.acquire()\n",
    "        self.caches.post_production(_new_content_name, social_publisher)\n",
    "        self.lock.release()\n",
    "    #consume_from_server(user,position, contentname)\n",
    "    def consume_from_server(self, social_issuer, position, content_name):\n",
    "        #print \"consume_from_server %s\"%content_name\n",
    "        # 首先将用户的位置进行更新为新的地点\n",
    "        self.topology_nodes.update_user_position(social_issuer, position)\n",
    "        # 然后\n",
    "        content_retrieved = {}\n",
    "        last = 0\n",
    "        #寻找到存储这个内容的节点\n",
    "        # Print Flag\n",
    "        #print(\"Consume: \",content_name)\n",
    "        for row in self.c.execute('SELECT * FROM catalog WHERE content_name == \\\"%s\\\" LIMIT 1'%( content_name )):\n",
    "            # row的格式是：\n",
    "            # content_name text, publisher int, date double, refer text, refered_level int, topic int\n",
    "            last = row[0]\n",
    "            reference = row[3]\n",
    "            referer_level = row[4]\n",
    "            topic = row[5]\n",
    "            interest = last\n",
    "            #从拓扑图中获取路径\n",
    "            # 由于获取的时候\n",
    "            # Print Flag\n",
    "            \n",
    "            path = self.topology_nodes.get_path(social_issuer, row[1])\n",
    "            # Retrieve content and calculate statistics\n",
    "            self.lock.acquire()\n",
    "            self.caches._retrieve_from_caches(interest, path)\n",
    "            self.lock.release()\n",
    "        if self.verbose:\n",
    "            print(self.printStats())\n",
    "\n",
    "    def consumer(self, social_issuer, position):\n",
    "        self.topology_nodes.update_user_position(social_issuer, position)\n",
    "        content_retrieved = {}\n",
    "        for social_neighbour in self.social_graph.neighbors(social_issuer):\n",
    "            topology_neighbour = self.topology_nodes[social_neighbour]\n",
    "            last = 0\n",
    "            \n",
    "            for row in self.c.execute('SELECT * FROM catalog WHERE publisher=%s and date BETWEEN %2f AND %2f ORDER BY date DESC LIMIT 1'%(social_neighbour, time.time()-0.2, time.time())):\n",
    "                last = row[0]\n",
    "                reference = row[3]\n",
    "                referer_level = row[4]\n",
    "                topic = row[5]\n",
    "                #detecting original consumer\n",
    "                while referer_level > 0:\n",
    "                    for row in self.c.execute('SELECT * FROM catalog WHERE content_name=\\\"%s\\\" ORDER BY date DESC LIMIT 1'%reference):\n",
    "                        last = row[0]\n",
    "                        reference = row[3]\n",
    "                        referer_level = row[4]\n",
    "                        topic = row[5]\n",
    "                #print row\n",
    "                interest = last\n",
    "                path = self.topology_nodes.get_path(social_issuer, social_neighbour)\n",
    "                self.lock.acquire()\n",
    "                self.caches._retrieve_from_caches(interest, path)\n",
    "                self.lock.release()\n",
    "            if self.verbose:\n",
    "                print(self.printStats())\n",
    "#########################################################\n",
    "    # TODO: 先从目标节点中尝试获取缓存信息，然后再尝试从Server处获取缓存信息\n",
    "    # Pending 02\n",
    "    def consume_from_target(self, consumer, content_name) :\n",
    "        # 目标节点\n",
    "        # Pending： 需要向目标节点发出请求\n",
    "        # target = hash_target(content_name)\n",
    "        content_retrieved = False\n",
    "        target = self.AS.get_node(content_name)\n",
    "        #print(\"Consume: \",content_name,\"Target is: \", target)\n",
    "        path_to_target = self.topology_nodes.get_path(consumer, target)\n",
    "        path_to_server = self.topology_nodes.get_path(consumer, self.server)\n",
    "        target_to_server = self.topology_nodes.get_path(target,self.server)\n",
    "        self.lock.acquire()\n",
    "        self.caches.retrieve_content(content_name, target, path_to_target,self.server, target_to_server)\n",
    "        #try:\n",
    "            #  从目标节点中进行获取内容\n",
    "            # retrieve_content(self, interest, target, path_to_target, server, path_to_server):\n",
    "        #    self.caches.retrieve_content(content_name, target, path_to_target,self.server, target_to_server)\n",
    "        #except:\n",
    "        #    self.caches._retrieve_from_caches(content_name, path_to_server)\n",
    "        self.lock.release()\n",
    "        #if self.verbose:\n",
    "        #    print(self.printStats())\n",
    "#########################################################\n",
    "    def get_expired_elements(self):\n",
    "        # get last element of each social user\n",
    "        #TODO: refactoring URGENT!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        return 0\n",
    "    def get_diversity(self):\n",
    "        return self.stats.get_diversity(self.caches)\n",
    "    def printStats(self):\n",
    "        return self.caches.stats_summary()\n",
    "    #############################################\n",
    "    # print cache detail\n",
    "    def printCaches(self):\n",
    "        return self.caches.print_caches()\n",
    "    ##############################################\n",
    "    def printStepSummary(self, timestamp):\n",
    "        print(\"=> {0} {1}\".format(timestamp, self.caches.stats_summary()))\n",
    "    def finishSimulation(self):\n",
    "        del self.caches\n",
    "        del self.topology_nodes \n",
    "        del self.sched\n",
    "        self.c.close()\n",
    "        self.lock.acquire()\n",
    "        self.lock.release()\n",
    "        self.condition.acquire()\n",
    "        self.condition.notify()\n",
    "        self.condition.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1b0e5d-527d-4124-91dd-3209fbee6ed3",
   "metadata": {},
   "source": [
    "# Clear logger block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e207196-cb6a-42fa-8086-be07dd970834",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('logger')\n",
    "while logger.handlers:\n",
    "    logger.handlers.pop()\n",
    "cache_info = logging.getLogger('cache_info')\n",
    "while cache_info.handlers:\n",
    "    cache_info.handlers.pop()\n",
    "    cache_info = logging.getLogger('cache_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5629c088-cfb8-4ab9-a86f-40ae3136883d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'logging' from '/Users/sijiazhang/miniforge3/envs/ccnsim/lib/python3.8/logging/__init__.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "logging.shutdown()\n",
    "reload(logging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223bfead-eff8-4cfb-9968-d3f310eaf230",
   "metadata": {},
   "source": [
    "## 4 😯Configure and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b514f4f-b19a-4a96-a684-88ec33956db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = setup_logger('logger','example.log', level = logging.INFO, format_style = '%(message)s',verbose = False)\n",
    "cache_info = setup_logger('cache_info','cache_info.log', level = logging.CRITICAL, format_style = '%(message)s',verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48563ff6-ee64-4e0a-a4ca-a294b3399675",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = '-c 10 -s pop -u facebook -t geant -p lru -f exampletrace/verysmall -d True -z True -e geographical -g True -v True'\n",
    "(options,args) = parser.parse_args(args.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59693cf6-9f03-4807-8528-77bc7c97a409",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c37aec9-7d95-4b54-9fd7-4ec8b1cf06d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-25 14:51:50,922 - root - INFO - Enable Debugging\n",
      "2021-05-25 14:51:50,923 - root - DEBUG - Mobility disabled\n",
      "2021-05-25 14:51:50,923 - root - DEBUG - Step printing activated\n",
      "2021-05-25 14:51:50,957 - root - DEBUG - Social Graph loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "initialized Autonomous System\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-25 14:51:50,965 - logger - INFO - initialized Autonomous System\n",
      "#####################################################################\n",
      "Round#  1\n",
      "Start Simulating!\n",
      "total seq num:  2000\n",
      "CPU times: user 222 ms, sys: 21.1 ms, total: 243 ms\n",
      "Wall time: 22 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sijiazhang/miniforge3/envs/ccnsim/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:427: FutureWarning: After 0.13 initialization must be handled at model creation\n",
      "  warnings.warn(\n",
      "/Users/sijiazhang/miniforge3/envs/ccnsim/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/sijiazhang/miniforge3/envs/ccnsim/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 1 , internal_hit: 1207 , internal_miss: 793 , stretch : 1925 , cacheHit: 0.0 , stretch: 0.0 hop_reduction: 0.0 get_diversity: 1.0 caching_operations: 793 eviction_operations: 793 Satisfied by caches: 0 _interest: 0, get_rch: 0\n",
      "#####################################################################\n",
      "Round#  2\n",
      "Start Simulating!\n",
      "total seq num:  4000\n",
      "CPU times: user 198 ms, sys: 18.2 ms, total: 216 ms\n",
      "Wall time: 42 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sijiazhang/miniforge3/envs/ccnsim/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:1439: RuntimeWarning: divide by zero encountered in log\n",
      "  aic = self.nobs * np.log(sse / self.nobs) + k * 2\n",
      "/Users/sijiazhang/miniforge3/envs/ccnsim/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:1444: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  aicc = aic + aicc_penalty\n",
      "/Users/sijiazhang/miniforge3/envs/ccnsim/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:1445: RuntimeWarning: divide by zero encountered in log\n",
      "  bic = self.nobs * np.log(sse / self.nobs) + k * np.log(self.nobs)\n",
      "/Users/sijiazhang/miniforge3/envs/ccnsim/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/sijiazhang/miniforge3/envs/ccnsim/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 2 , internal_hit: 1203 , internal_miss: 797 , stretch : 1881 , cacheHit: 0.0 , stretch: 0.0 hop_reduction: 0.0 get_diversity: 1.0 caching_operations: 797 eviction_operations: 797 Satisfied by caches: 0 _interest: 0, get_rch: 0\n",
      "#####################################################################\n",
      "Round#  3\n",
      "Start Simulating!\n",
      "total seq num:  6000\n",
      "CPU times: user 189 ms, sys: 17.7 ms, total: 207 ms\n",
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sijiazhang/miniforge3/envs/ccnsim/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/sijiazhang/miniforge3/envs/ccnsim/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 3 , internal_hit: 1363 , internal_miss: 637 , stretch : 1485 , cacheHit: 0.0 , stretch: 0.0 hop_reduction: 0.0 get_diversity: 1.0 caching_operations: 141 eviction_operations: 141 Satisfied by caches: 0 _interest: 0, get_rch: 0\n",
      "#####################################################################\n",
      "Round#  4\n",
      "Start Simulating!\n",
      "total seq num:  8000\n",
      "CPU times: user 188 ms, sys: 18.4 ms, total: 206 ms\n",
      "Wall time: 1min 22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sijiazhang/miniforge3/envs/ccnsim/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/sijiazhang/miniforge3/envs/ccnsim/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 4 , internal_hit: 1446 , internal_miss: 554 , stretch : 1299 , cacheHit: 0.0 , stretch: 0.0 hop_reduction: 0.0 get_diversity: 1.0 caching_operations: 43 eviction_operations: 43 Satisfied by caches: 0 _interest: 0, get_rch: 0\n",
      "#####################################################################\n",
      "Round#  5\n",
      "Start Simulating!\n",
      "total seq num:  10000\n",
      "CPU times: user 184 ms, sys: 18.5 ms, total: 202 ms\n",
      "Wall time: 1min 42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sijiazhang/miniforge3/envs/ccnsim/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/sijiazhang/miniforge3/envs/ccnsim/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 5 , internal_hit: 1441 , internal_miss: 559 , stretch : 1300 , cacheHit: 0.0 , stretch: 0.0 hop_reduction: 0.0 get_diversity: 1.0 caching_operations: 12 eviction_operations: 12 Satisfied by caches: 0 _interest: 0, get_rch: 0\n",
      "#####################################################################\n",
      "Round#  6\n",
      "Start Simulating!\n",
      "total seq num:  12000\n",
      "CPU times: user 187 ms, sys: 19.4 ms, total: 207 ms\n",
      "Wall time: 2min 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sijiazhang/miniforge3/envs/ccnsim/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/sijiazhang/miniforge3/envs/ccnsim/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 6 , internal_hit: 1473 , internal_miss: 527 , stretch : 1239 , cacheHit: 0.0 , stretch: 0.0 hop_reduction: 0.0 get_diversity: 1.0 caching_operations: 5 eviction_operations: 5 Satisfied by caches: 0 _interest: 0, get_rch: 0\n",
      "#####################################################################\n",
      "Round#  7\n",
      "Start Simulating!\n",
      "total seq num:  14000\n",
      "CPU times: user 183 ms, sys: 18.9 ms, total: 202 ms\n",
      "Wall time: 2min 22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sijiazhang/miniforge3/envs/ccnsim/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/sijiazhang/miniforge3/envs/ccnsim/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 7 , internal_hit: 1431 , internal_miss: 569 , stretch : 1330 , cacheHit: 0.0 , stretch: 0.0 hop_reduction: 0.0 get_diversity: 1.0 caching_operations: 4 eviction_operations: 4 Satisfied by caches: 0 _interest: 0, get_rch: 0\n",
      "#####################################################################\n",
      "Round#  8\n",
      "Start Simulating!\n",
      "total seq num:  16000\n",
      "CPU times: user 202 ms, sys: 21 ms, total: 223 ms\n",
      "Wall time: 2min 42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sijiazhang/miniforge3/envs/ccnsim/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/sijiazhang/miniforge3/envs/ccnsim/lib/python3.8/site-packages/statsmodels/tsa/holtwinters/model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 8 , internal_hit: 1449 , internal_miss: 551 , stretch : 1297 , cacheHit: 0.0 , stretch: 0.0 hop_reduction: 0.0 get_diversity: 1.0 caching_operations: 2 eviction_operations: 2 Satisfied by caches: 0 _interest: 0, get_rch: 0\n",
      "#####################################################################\n",
      "Round#  9\n",
      "Start Simulating!\n",
      "total seq num:  18000\n"
     ]
    }
   ],
   "source": [
    "#logger = setup_logger('logger', 'example.log', level=logging.INFO)\n",
    "if options.debug:\n",
    "    root = logging.getLogger()\n",
    "    root.setLevel(logging.DEBUG)\n",
    "    ch = logging.StreamHandler(sys.stdout)\n",
    "    ch.setLevel(logging.DEBUG)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    ch.setFormatter(formatter)\n",
    "    root.addHandler(ch)\n",
    "    root.info('Enable Debugging')\n",
    "    # delivering original parameters\n",
    "CACHE_SIZE = options.cache_size_per_node\n",
    "CACHING_STRATEGY = options.caching_strategy\n",
    "## Configure Cache\n",
    "RUNS = 10\n",
    "SOCIAL_GRAPH = options.social_graph\n",
    "TOPOLOGY_GRAPH = options.network_topology\n",
    "CACHE_STRUCTURE = options.replacement_policy\n",
    "SEQUENCE_FILE = options.trace\n",
    "ZIPF = options.zipf\n",
    "SINGLE = options.single\n",
    "VERBOSE = options.verbose\n",
    "if SEQUENCE_FILE == \"\":\n",
    "    logging.error(\"no trace file, using random generation of messages.\")\n",
    "    exit()\n",
    "METHOD = options.method\n",
    "if METHOD not in ['random','geographical','onepublisher']:\n",
    "    root.error(\"WARNING, method is not listed, set to random\")\n",
    "    METHOD = 'random'\n",
    "MOBILITY_ENABLED = options.mobility_enabled\n",
    "if MOBILITY_ENABLED:\n",
    "    root.debug(\"Mobility enabled\")\n",
    "else:\n",
    "    root.debug(\"Mobility disabled\")\n",
    "\n",
    "try:\n",
    "    STEP_PRINTING = [float(x) for x in options.step_printing.split(\",\") if x != '']\n",
    "    root.debug(\"Step printing activated\")\n",
    "except IndexError:\n",
    "    STEP_PRINTING = []\n",
    "    root.debug(\"Step printing not activated\")\n",
    "CACHE_STRUCTURE = re.match('([a-zA-Z0-9_]*(\\((?P<params>([0-9]*\\.?[0-9]*,? ?)*)\\))?)', CACHE_STRUCTURE)\n",
    "assert CACHE_STRUCTURE != None\n",
    "CACHE_STRUCTURE = CACHE_STRUCTURE.group(1)\n",
    "# Import Social Graph\n",
    "# Social Graph from folder graphs\n",
    "G = getattr(__import__('graphs.%s'%SOCIAL_GRAPH), SOCIAL_GRAPH).G\n",
    "#plotGraph(G)\n",
    "root.debug('Social Graph loaded')\n",
    "#random.seed(10442)\n",
    "# Import Topology Graph as a new class(peterson and pharse as topology class)\n",
    "# social_graph is imported as a new class from folder graph, in this case, alibama\n",
    "petersen = getattr(__import__('graphs.%s'%TOPOLOGY_GRAPH), TOPOLOGY_GRAPH).G\n",
    "#plotGraph(petersen)\n",
    "# social_graph, topology, cache_size, caching_strategy, cache_policy, sequence_filename, mobility_enabled, step_printing, topology_file\n",
    "executor = Executor(logger,G, petersen, CACHE_SIZE, CACHING_STRATEGY, CACHE_STRUCTURE, SEQUENCE_FILE, MOBILITY_ENABLED, STEP_PRINTING, topology_file=TOPOLOGY_GRAPH, zipf = ZIPF, method = METHOD, single = SINGLE, verbose = VERBOSE) \n",
    "offset = [0,2,4,6,8,10,12,14,16,18,20]\n",
    "for i in range(0, RUNS):\n",
    "    #print(executor.caches.print_caches())\n",
    "    print(\"#####################################################################\")\n",
    "    print(\"Round# \", i+1)\n",
    "    %time executor.run(offset = offset[i])\n",
    "    executor.caches.update_predict_result()\n",
    "    print(executor.printStats())\n",
    "    result.append(executor.caches.stats._internal_hit)\n",
    "    #print(executor.caches.print_caches())\n",
    "    executor.caches.stats.reset()\n",
    "    #print(executor.caches.pop)\n",
    "executor.finishSimulation()\n",
    "root.handlers.pop()\n",
    "logger = logging.getLogger('logger')\n",
    "while logger.handlers:\n",
    "    logger.handlers.pop()\n",
    "cache_info = logging.getLogger('cache_info')\n",
    "while cache_info.handlers:\n",
    "    cache_info.handlers.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a362c16-9f15-41c8-b9f0-388c82e13360",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = [0,2,4,6,8,10,12,14,16,18,20]\n",
    "contents = [\"/content/%s\"%str(i) for i in range(1000)]\n",
    "patterns = {}\n",
    "for i in range(len(offset)):\n",
    "    req, pattern = gen_bilateral_biased_zipf_requests(alpha = 1,number_of_content = 1000, number_of_request = 10000, offset = offset[i])\n",
    "    patterns[i] = pattern\n",
    "data = []\n",
    "for i in range(len(offset)):\n",
    "    data.append(patterns[i][15])\n",
    "plt.plot(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577ae5e2-e007-428c-a2d2-50ae14e01d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'/content/34': 2    0.085694\n",
    "dtype: float64, '/content/384': 2    0.505546\n",
    "dtype: float64, '/content/56': 2    0.170837\n",
    "dtype: float64, '/content/205': 2    0.338307\n",
    "dtype: float64, '/content/371': 2    0.505546\n",
    "dtype: float64, '/content/360': 2    0.505546\n",
    "dtype: float64, '/content/406': 2    0.338307\n",
    "dtype: float64, '/content/813': 2    0.505546\n",
    "dtype: float64, '/content/418': 2    0.505546\n",
    "dtype: float64, '/content/441': 2    0.505546\n",
    "dtype: float64, '/content/215': 2    0.505546\n",
    "dtype: float64, '/content/741': 2    0.505546\n",
    "dtype: float64, '/content/186': 2    0.505546\n",
    "dtype: float64, '/content/740': 2    0.505546\n",
    "dtype: float64, '/content/617': 2    0.505546\n",
    "dtype: float64, '/content/790': 2    0.505546\n",
    "dtype: float64, '/content/965': 2    0.505546\n",
    "dtype: float64, '/content/210': 2    0.505546\n",
    "dtype: float64}\n",
    "sorted(data, key = lambda: d: d[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9141f85c-720f-48cc-a2db-12b2c04199dc",
   "metadata": {},
   "source": [
    "## 5 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc032fef-580d-4525-ae35-907a718aef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1bbd73-df6d-482b-896a-40e147bf6be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOPOLOGY_GRAPH = options.network_topology\n",
    "#G = getattr(__import__('graphs.%s'%TOPOLOGY_GRAPH), TOPOLOGY_GRAPH).G\n",
    "G = executor.topology\n",
    "topo_vis = vis(G, executor.topology_coords)\n",
    "node = random.choice(list(G.nodes()))\n",
    "G.add_node(\"server\", label = \"server\")\n",
    "G.add_edge(node,\"server\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b32955d-9755-454d-98e8-93920e662bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS1 = AS(list(G.nodes()),True)\n",
    "print(AS1.get_nodes())\n",
    "AS1.get_node(\"coconut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0d1abf-9067-479e-9583-e51a7af3870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "        pos = executor.topology_coords\n",
    "        Gcc = G.subgraph(sorted(nx.connected_components(G), key=len, reverse=True)[0])\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        ax0 = fig.subplots()\n",
    "        nx.draw_networkx_nodes(G, pos,  node_size = 80)\n",
    "        nx.draw_networkx_edges(G,pos, alpha = 0.6)\n",
    "        pos1 = {}\n",
    "        for p in pos:  # raise text positions\n",
    "            #pos[p] = [p[0]+0.05, p[1]+0.04]\n",
    "            pos1[p] = pos[p][0]+0.005,pos[p][1]+0.003\n",
    "        plt.title('label graph')\n",
    "        nx.draw_networkx_labels(G, pos1,  font_size = 20)\n",
    "        plt.show()\n",
    "        #print(pos, pos1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8010532-2713-4e7f-a134-904d02bfc30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, font_size=16)\n",
    "for p in pos:  # raise text positions\n",
    "    pos[p][0] += 0.05\n",
    "    pos[p][1] += 0.09\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b4e37a-7adb-478e-bc20-32d808fbc0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "topo_vis.label_graph(font_size = 1, node_size = 210)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba110fe-8958-4b01-9f6d-f474af781b0c",
   "metadata": {},
   "source": [
    "# 节点的介度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d68a7e8-457e-478d-9dc2-84489bc362f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Betweenness\")\n",
    "b = nx.betweenness_centrality(G)\n",
    "for v in G.nodes():\n",
    "    print(\"%0.2d %5.3f\" % (v, b[v]))\n",
    "\n",
    "print(\"Degree centrality\")\n",
    "d = nx.degree_centrality(G)\n",
    "for v in G.nodes():\n",
    "    print(\"%0.2d %5.3f\" % (v, d[v]))\n",
    "\n",
    "print(\"Closeness centrality\")\n",
    "c = nx.closeness_centrality(G)\n",
    "for v in G.nodes():\n",
    "    print(\"%0.2d %5.3f\" % (v, c[v]))\n",
    "\n",
    "nx.draw(G, pos, font_size=16)\n",
    "for p in pos:  # raise text positions\n",
    "    pos[p][0] += 0.05\n",
    "    pos[p][1] += 0.09\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c1d6c9-11e4-42b6-9b4c-d794b29174e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(d.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd4c638-f531-4c3e-9866-259d59475101",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(44/21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262eeb3c-0058-4638-9b93-f59d9f98b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOCIAL_GRAPH = options.social_graph\n",
    "G = getattr(__import__('graphs.%s'%SOCIAL_GRAPH), SOCIAL_GRAPH).G\n",
    "social_vis = vis(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c464a85c-7913-445f-8dff-705ea052b262",
   "metadata": {},
   "outputs": [],
   "source": [
    "social_vis.degree_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc65b6-751c-4d63-8b82-2df4d48b9321",
   "metadata": {},
   "outputs": [],
   "source": [
    "social_vis.simple_graph(node_size = 10, alpha = 0.2, size = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469c89b5-05be-4c1c-85a3-bd760256ec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Betweenness\")\n",
    "b = nx.betweenness_centrality(G)\n",
    "for v in G.nodes():\n",
    "    print(\"%0.2d %5.3f\" % (v, b[v]))\n",
    "\n",
    "print(\"Degree centrality\")\n",
    "d = nx.degree_centrality(G)\n",
    "for v in G.nodes():\n",
    "    print(\"%0.2d %5.3f\" % (v, d[v]))\n",
    "\n",
    "print(\"Closeness centrality\")\n",
    "c = nx.closeness_centrality(G)\n",
    "for v in G.nodes():\n",
    "    print(\"%0.2d %5.3f\" % (v, c[v]))\n",
    "\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, font_size=16)\n",
    "for p in pos:  # raise text positions\n",
    "    pos[p][0] += 0.05\n",
    "    pos[p][1] += 0.09\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48a4eff-e11e-463a-975d-701b5d1e2901",
   "metadata": {},
   "outputs": [],
   "source": [
    "topo_vis.directed_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85c91b9-d4b1-4802-a1ca-aa6a577a6960",
   "metadata": {},
   "outputs": [],
   "source": [
    "topo_vis.degree_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7600385-d2c4-4575-82d7-94b472cc8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "topo_vis.simple_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9a7e91-dd3c-421a-89c9-a25c77566f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = '-c 2 -s lce -u facebook -t geant -p lru -f exampletrace/verysmall -d True'\n",
    "(options,args) = parser.parse_args(args.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26db62f-9846-47fa-bb95-49cd6d12515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPOLOGY_GRAPH = options.network_topology\n",
    "G = getattr(__import__('graphs.%s'%TOPOLOGY_GRAPH), TOPOLOGY_GRAPH).G\n",
    "topo_vis = vis(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d792932-0bd6-4d32-b86c-79d858af9aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "topo_vis.degree_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()  # or DiGraph, MultiGraph, MultiDiGraph, etc\n",
    "G.add_nodes_from(\"Hello\")\n",
    "K3 = nx.Graph([(0, 1), (1, 2), (2, 0)])\n",
    "G.add_nodes_from(K3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1099a6f5-c180-420d-aa78-e0ad3fea52ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "viser = vis(G)\n",
    "viser.directed_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04f33c6-fd1a-4c6f-82c2-0b95cb47c502",
   "metadata": {},
   "outputs": [],
   "source": [
    "viser.degree_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c811f7-9c13-43fb-b8bb-535d81a3ffdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a436db-f18f-4c0e-9a86-b9b322d3c031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
